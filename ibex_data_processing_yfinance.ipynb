{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGAMOS LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import fastparquet\n",
    "import awswrangler as wr\n",
    "import os\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INICIALIZAMOS UNA SESION EN AWS\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.environ['S3_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_SECRET_KEY'],\n",
    "    region_name=os.environ['S3_REGION'])\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "ibex_historical_data = {}\n",
    "bucket_name = 'stock-market-historical-data'\n",
    "raw_folder = 'raw/yfinance/'\n",
    "pre_folder = 'preprocessed/yfinance/'\n",
    "pro_folder = 'processed/yfinance/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJETIVO DE ESTE NOTEBOOK:\n",
    "- DESCARGAR DE DISTINTOS ORIGENES LOS DATOS DE LOS ACTIVOS DEL IBEX35\n",
    "- COMPARAR LOS DATOS OBTENIDOS "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGA DE COMPOSICIÓN HISTÓRICA DE IBEX35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activo</th>\n",
       "      <th>Inclusion</th>\n",
       "      <th>Exclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACE</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2003-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACX</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1991-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1991-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASL</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1994-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBV</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2000-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activo  Inclusion  Exclusion\n",
       "0    ACE 1991-01-02 2003-06-02\n",
       "1    ACX 1991-01-02 1991-07-01\n",
       "2    ALB 1991-01-02 1991-07-01\n",
       "3    ASL 1991-01-02 1994-01-03\n",
       "4    BBV 1991-01-02 2000-01-31"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LEEMOS EL FICHERO CON LA COMPOSICIÓN HISTORICA\n",
    "ibex_constituents = pd.read_excel('data_processing/Historical Composition IBEX35.xlsx')\n",
    "ibex_constituents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibex_constituents['Exclusion'] -= BDay(1)\n",
    "\n",
    "# ibex_constituents['Inclusion'] = ibex_constituents['Inclusion'].dt.date\n",
    "# ibex_constituents['Exclusion'] = ibex_constituents['Exclusion'].dt.date\n",
    "\n",
    "# OBTENEMOS EL DIA ACTUAL\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# COMPLETAMOS LOS DATOS NULOS EN EL FICHERO DE COMPOSICIÓN HISTORICA CON LA FECHA ACTUAL\n",
    "ibex_constituents.fillna(today,inplace=True)\n",
    "\n",
    "# DEFINIMOS UNA VARIABLE PARA TODOS LOS ACTIVOS\n",
    "activos = ibex_constituents.Activo\n",
    "ibex_constituents['Ticker'] = activos.apply(lambda x: x.split('_')[0])\n",
    "\n",
    "unique_activos = list(set(activos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activo</th>\n",
       "      <th>Inclusion</th>\n",
       "      <th>Exclusion</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BKT</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>BKT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IBE</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>IBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>REP</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>REP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEF</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>TEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACS</td>\n",
       "      <td>1998-04-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ACS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>FER</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>FER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>IDR</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>IDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>BBVA</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>BBVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ITX</td>\n",
       "      <td>2001-07-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ITX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SAN_1</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>SAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ENG</td>\n",
       "      <td>2003-01-10</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>SAB</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>SAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>MAP_2</td>\n",
       "      <td>2006-07-25</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>MAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>GRF</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>GRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>MTS</td>\n",
       "      <td>2009-05-05</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>MTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>AMS_1</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>AMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>IAG</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>IAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>CABK</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>CABK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>SCYR_2</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>SCYR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>ELE_1</td>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ELE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>ACX_2</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ACX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>AENA</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>AENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>ANA_2</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>MRL</td>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>MRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>CLNX</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>CLNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>MEL</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>MEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>COL_1</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NTGY</td>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>NTGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>SLR</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>SLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>FDR</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ROVI</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ROVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>RED</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ANE</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>ANE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>LOG</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>LOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>UNI_1</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>2023-08-27</td>\n",
       "      <td>UNI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Activo  Inclusion  Exclusion Ticker\n",
       "5       BKT 1991-01-02 2023-08-27    BKT\n",
       "18      IBE 1991-01-02 2023-08-27    IBE\n",
       "21      REP 1991-01-02 2023-08-27    REP\n",
       "25      TEF 1991-01-02 2023-08-27    TEF\n",
       "71      ACS 1998-04-02 2023-08-27    ACS\n",
       "79      FER 1999-07-01 2023-08-27    FER\n",
       "80      IDR 1999-07-01 2023-08-27    IDR\n",
       "85     BBVA 2000-01-31 2023-08-27   BBVA\n",
       "95      ITX 2001-07-02 2023-08-27    ITX\n",
       "96    SAN_1 2001-11-01 2023-08-27    SAN\n",
       "101     ENG 2003-01-10 2023-08-27    ENG\n",
       "108     SAB 2004-07-01 2023-08-27    SAB\n",
       "116   MAP_2 2006-07-25 2023-08-27    MAP\n",
       "123     GRF 2008-01-02 2023-08-27    GRF\n",
       "129     MTS 2009-05-05 2023-08-27    MTS\n",
       "132   AMS_1 2011-01-03 2023-08-27    AMS\n",
       "133     IAG 2011-04-01 2023-08-27    IAG\n",
       "134    CABK 2011-07-01 2023-08-27   CABK\n",
       "141  SCYR_2 2022-06-20 2023-08-27   SCYR\n",
       "145   ELE_1 2014-12-22 2023-08-27    ELE\n",
       "146   ACX_2 2015-06-22 2023-08-27    ACX\n",
       "147    AENA 2015-06-22 2023-08-27   AENA\n",
       "148   ANA_2 2015-07-20 2023-08-27    ANA\n",
       "149     MRL 2015-12-21 2023-08-27    MRL\n",
       "150    CLNX 2016-06-21 2023-08-27   CLNX\n",
       "152     MEL 2016-08-08 2023-08-27    MEL\n",
       "153   COL_1 2017-06-16 2023-08-27    COL\n",
       "155    NTGY 2018-07-02 2023-08-27   NTGY\n",
       "161     SLR 2020-10-19 2023-08-27    SLR\n",
       "162     FDR 2021-03-29 2023-08-27    FDR\n",
       "163    ROVI 2021-12-20 2023-08-27   ROVI\n",
       "164     RED 2022-06-13 2023-08-27    RED\n",
       "165     ANE 2022-06-20 2023-08-27    ANE\n",
       "166     LOG 2022-12-19 2023-08-27    LOG\n",
       "167   UNI_1 2022-12-27 2023-08-27    UNI"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_constituents = ibex_constituents.loc[ibex_constituents['Exclusion'] == today]\n",
    "current_constituents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DESCARGAMOS LOS DATOS DE YAHOO FINANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_parquet_to_s3(bucket_name, file_name, folder_name, dataframe):\n",
    "    full_path = folder_name + file_name + '.parquet'\n",
    "    s3 = boto3.resource('s3')\n",
    "    table = pa.Table.from_pandas(dataframe)\n",
    "    buf = BytesIO()\n",
    "    pq.write_table(table, buf)\n",
    "    s3.Object(bucket_name, full_path).put(Body=buf.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibex_constituents[ibex_constituents['Activo']=='SOL'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2003-01-02 00:00:00')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibex_constituents.Exclusion[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "                 Open       High        Low      Close  Adj Close    Volume\n",
      "Date                                                                       \n",
      "2000-01-03  13.690602  13.757854  13.594527  13.623349   4.755257   8244257\n",
      "2000-01-04  13.450416  13.536882  13.219837  13.267874   4.631179   8522096\n",
      "2000-01-05  13.142977  13.210230  12.912399  12.970044   4.527219  12159826\n",
      "2000-01-06  12.970044  12.970044  12.970044  12.970044   4.527219         0\n",
      "2000-01-07  13.248659  13.248659  12.998866  13.133370   4.584228  62261944\n",
      "2000-01-10  13.277482  13.277482  12.902791  12.922006   4.510450  58740351\n",
      "2000-01-11  12.873969  12.893184  12.537709  12.662605   4.419908   6761292\n",
      "2000-01-12  12.643391  12.643391  12.393597  12.518494   4.405469   8266754\n",
      "2000-01-13  12.489672  12.537709  12.105374  12.211056   4.297278   9372669\n",
      "2000-01-14  12.297523  12.480064  12.230271  12.451242   4.381802   8538333\n",
      "2000-01-17  12.537709  12.537709  12.307130  12.335952   4.341231   6825078\n",
      "2000-01-18  12.307130  12.326345  11.942047  12.076552   4.249946   9698972\n",
      "2000-01-19  11.855580  12.057337  11.817151  12.057337   4.243181  13027455\n",
      "2000-01-20  12.105374  12.163019  11.922833  12.038122   4.236421   9459285\n",
      "2000-01-21  11.942047  12.009300  11.749899  11.788328   4.148513   6786146\n",
      "2000-01-24  12.047729  12.047729  11.817151  11.845973   4.168800   5863878\n",
      "2000-01-25  11.836366  12.259093  11.797936  12.105374   4.260087   9429700\n",
      "2000-01-26  12.297523  12.537709  12.153411  12.480064   4.391946   9120798\n",
      "2000-01-27  12.614568  13.114155  12.547316  12.970044   4.564378  13662088\n",
      "2000-01-28  13.171800  13.171800  12.585746  12.922006   4.547472  16119882\n",
      "BBV\n"
     ]
    }
   ],
   "source": [
    "# REALIZAMOS LA DESCARGA DE LOS DATOS DE YFINANCE Y LOS CARGAMOS EN UN BUCKET DE S3\n",
    "\n",
    "failed_loads = []\n",
    "i = ibex_constituents[ibex_constituents['Activo']=='BBV'].index[0]\n",
    "\n",
    "ticker = 'BBVA' + '.MC'\n",
    "print(i)\n",
    "file_name = ibex_constituents.Activo[i] +'.parquet'\n",
    "start_date = ibex_constituents.Inclusion[i]\n",
    "end_date = ibex_constituents.Exclusion[i]\n",
    "full_path = preprocessed_folder + file_name\n",
    "\n",
    "stock = yf.download(ticker, start=start_date, end=end_date)\n",
    "print(stock)\n",
    "stock = pd.DataFrame(stock)\n",
    "\n",
    "table = pa.Table.from_pandas(stock)\n",
    "buf = BytesIO()\n",
    "pq.write_table(table, buf)\n",
    "\n",
    "s3.Object(bucket_name, full_path).put(Body=buf.getvalue())\n",
    "print(ibex_constituents.Activo[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date\n",
       "2000-01-03   -12.893392\n",
       "2000-01-04   -12.997465\n",
       "2000-01-05   -12.488667\n",
       "2000-01-07   -12.893392\n",
       "2000-01-10   -13.032155\n",
       "                ...    \n",
       "2002-12-19     3.502554\n",
       "2002-12-20     3.571063\n",
       "2002-12-23     3.571063\n",
       "2002-12-27     3.451172\n",
       "2002-12-30     3.228515\n",
       "Name: Adj Close, Length: 743, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_prices = pq.read_table(download_s3_parquet_file(s3, bucket_name,'preprocessed/yfinance/SOL.parquet')).to_pandas()\n",
    "stock_prices.index = pd.to_datetime(stock_prices.index).strftime('%Y-%m-%d')\n",
    "negative_adj_close = stock_prices[stock_prices['Adj Close']<0]\n",
    "if negative_adj_close.empty:\n",
    "    close_price = stock_prices['Adj Close']\n",
    "else:\n",
    "    close_price = stock_prices['Close']\n",
    "\n",
    "close_price.index = pd.to_datetime(close_price.index).strftime('%Y-%m-%d')\n",
    "close_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = bucket_name + pre_folder\n",
    "objects_dict = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix =pre_folder)\n",
    "pre_filepaths = [item['Key'] for item in objects_dict['Contents'] if item['Key'].endswith('.parquet')]\n",
    "act_list = [i.split('/')[-1].replace('.parquet','') for i in raw_filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'ibex_historical_data'\n",
    "full_path = processed_folder + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3_parquet_file(s3, bucket, key):\n",
    "    buffer = BytesIO()\n",
    "    s3.Object(bucket, key).download_fileobj(buffer)\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'stock-market-historical-data'\n",
    "pre_folder = 'preprocessed/yfinance/'\n",
    "pre_path = bucket_name + pre_folder\n",
    "objects_dict = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix =pre_folder)\n",
    "raw_filepaths = [item['Key'] for item in objects_dict['Contents'] if item['Key'].endswith('.parquet')]\n",
    "act_list = [i.split('/')[-1].replace('.parquet','') for i in raw_filepaths]\n",
    "current_constituents_filepath = [pre_folder + act + '.parquet' for act in current_constituents.Activo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# REALIZAMOS LA DESCARGA DE LOS DATOS DE MARKETSTACK Y LOS CARGAMOS EN UN BUCKET DE S3\n",
    "bucket_name = 'stock-market-historical-data'\n",
    "raw_folder = 'preprocessed/yfinance/'\n",
    "s3 = boto3.resource('s3')\n",
    "failed_loads = []\n",
    "for i in range(1,len(current_constituents_filepath)):\n",
    "    act_data = pq.read_table(download_s3_parquet_file(s3, bucket_name,current_constituents_filepath[i])).to_pandas()\n",
    "    act_data.index = pd.to_datetime(act_data.index)\n",
    "    act_data.sort_index(inplace=True)\n",
    "    date = act_data.index[-1] + datetime.timedelta(days=1)\n",
    "\n",
    "\n",
    "    new_data = yf.download(current_constituents.Ticker.iloc[i]+'.MC', start=date)\n",
    "    new_data.index = pd.to_datetime(new_data.index)\n",
    "\n",
    "    act_data = pd.DataFrame(act_data)\n",
    "    act_data = pd.concat([act_data,new_data], axis=0)\n",
    "    act_data.sort_index(inplace=True)\n",
    "\n",
    "    table = pa.Table.from_pandas(act_data)\n",
    "    buf = BytesIO()\n",
    "    pq.write_table(table, buf)\n",
    "\n",
    "    s3.Object(bucket_name, current_constituents_filepath[i]).put(Body=buf.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close   Volume\n",
      "Date                                                                      \n",
      "2000-07-03  40.500000  42.250000  39.500000  41.650002  -1.961556    46596\n",
      "2000-07-04  42.000000  42.150002  40.400002  40.599998  -1.912106    83363\n",
      "2000-07-05  40.610001  41.099998  39.900002  40.000000  -1.883848   202897\n",
      "2000-07-06  40.099998  41.299999  40.099998  40.660000  -1.914931   196208\n",
      "2000-07-10  41.299999  41.599998  41.099998  41.240002  -1.942247   169478\n",
      "...               ...        ...        ...        ...        ...      ...\n",
      "2001-01-08  39.900002  41.099998  39.500000  41.049999  -1.933298   146029\n",
      "2001-01-09  41.099998  41.750000  39.709999  40.150002  -1.890912   148356\n",
      "2001-01-10  40.250000  40.439999  39.900002  40.400002  -1.902686   110611\n",
      "2001-01-11  40.470001  40.799999  40.290001  40.650002  -1.914460  1063247\n",
      "2001-01-12  40.360001  41.200001  40.099998  41.000000  -1.930944   191471\n",
      "\n",
      "[131 rows x 6 columns]\n",
      "preprocessed/yfinance/ANA_1.parquet\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close   Volume\n",
      "Date                                                                      \n",
      "2000-01-03  19.700001  19.750000  18.879999  19.010000  -4.884562  3615680\n",
      "2000-01-04  18.879999  18.879999  18.200001  18.500000  -4.753520  4048543\n",
      "2000-01-05  18.200001  18.680000  18.129999  18.639999  -4.789490  4688995\n",
      "2000-01-07  18.900000  19.350000  18.860001  19.309999  -4.961645  4027102\n",
      "2000-01-10  19.549999  19.549999  19.059999  19.309999  -4.961645  2533020\n",
      "...               ...        ...        ...        ...        ...      ...\n",
      "2000-06-26  21.280001  21.320000  20.850000  21.250000  -5.460122  5896996\n",
      "2000-06-27  21.100000  21.340000  20.809999  20.850000  -5.357343  3900422\n",
      "2000-06-28  20.850000  20.900000  20.500000  20.690001  -5.316232  7792265\n",
      "2000-06-29  20.690001  20.770000  20.090000  20.160000  -5.180052  4060382\n",
      "2000-06-30  20.250000  20.500000  20.090000  20.290001  -5.213454  3817463\n",
      "\n",
      "[124 rows x 6 columns]\n",
      "preprocessed/yfinance/ELE.parquet\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Open       High        Low      Close  Adj Close  Volume\n",
      "Date                                                                     \n",
      "2000-01-07  13.654850  13.840339  13.505032  13.840339  -0.662828  446713\n",
      "2000-01-10  14.254122  14.254122  13.897413  13.911681  -0.666245  365016\n",
      "2000-01-11  13.890278  14.018694  13.447958  13.619179  -0.652237  362828\n",
      "2000-01-12  13.612045  13.983023  13.219664  13.961620  -0.668636  418190\n",
      "2000-01-13  13.840339  14.011560  13.398019  13.433690  -0.643353  308696\n",
      "...               ...        ...        ...        ...        ...     ...\n",
      "2000-06-26  14.411075  14.553759  14.097170  14.318330  -0.685720  368365\n",
      "2000-06-27  14.553759  14.682174  13.733326  13.840339  -0.662828  428383\n",
      "2000-06-28  13.904547  14.068633  13.676253  13.768997  -0.659411  222847\n",
      "2000-06-29  13.940218  13.940218  13.483629  13.483629  -0.645745  240083\n",
      "2000-06-30  13.754729  14.753516  13.376616  14.125707  -0.676495  516174\n",
      "\n",
      "[126 rows x 6 columns]\n",
      "preprocessed/yfinance/FCC.parquet\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Open   High    Low  Close  Adj Close   Volume\n",
      "Date                                                      \n",
      "2000-10-03  12.20  12.76  12.19  12.34  -0.579203   498316\n",
      "2000-10-04  12.40  12.65  12.34  12.53  -0.588121   395452\n",
      "2000-10-05  12.66  12.68  12.31  12.31  -0.577795   181875\n",
      "2000-10-06  12.47  12.49  12.25  12.29  -0.576856   215041\n",
      "2000-10-09  12.38  12.45  12.00  12.03  -0.564653   372529\n",
      "...           ...    ...    ...    ...        ...      ...\n",
      "2001-06-25  10.80  10.89  10.53  10.53  -0.494247  1216107\n",
      "2001-06-26  10.53  10.69   9.98  10.18  -0.477819  2096148\n",
      "2001-06-27  10.30  10.65  10.25  10.65  -0.499880  1220763\n",
      "2001-06-28  10.70  10.90  10.25  10.84  -0.508798   675831\n",
      "2001-06-29  10.87  10.90  10.33  10.40  -0.488145   808290\n",
      "\n",
      "[191 rows x 6 columns]\n",
      "preprocessed/yfinance/IDR.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Open   High    Low  Close  Adj Close    Volume\n",
      "Date                                                       \n",
      "2001-07-02  3.758  3.840  3.728  3.820  -0.136871   8634625\n",
      "2001-07-03  3.772  3.822  3.772  3.820  -0.136871  20450495\n",
      "2001-07-04  3.820  3.830  3.766  3.796  -0.136011   4993255\n",
      "2001-07-05  3.796  3.810  3.730  3.730  -0.133647  16127145\n",
      "2001-07-06  3.760  3.760  3.700  3.700  -0.132572   6726610\n",
      "...           ...    ...    ...    ...        ...       ...\n",
      "2002-09-18  4.062  4.098  4.000  4.052  -0.146037   4711710\n",
      "2002-09-19  4.022  4.150  3.960  4.020  -0.144884   9985435\n",
      "2002-09-20  4.076  4.350  3.966  4.280  -0.154255  16214830\n",
      "2002-09-23  4.210  4.228  4.082  4.200  -0.151371   8471515\n",
      "2002-09-24  4.200  4.260  4.106  4.200  -0.151371   8724120\n",
      "\n",
      "[308 rows x 6 columns]\n",
      "preprocessed/yfinance/ITX.parquet\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "             Open   High    Low  Close  Adj Close  Volume\n",
      "Date                                                     \n",
      "2000-01-03  11.60  11.60  11.05  11.15 -12.893392  164558\n",
      "2000-01-04  11.00  11.50  10.77  11.24 -12.997465  201679\n",
      "2000-01-05  10.91  11.44  10.80  10.80 -12.488667  165066\n",
      "2000-01-07  11.29  11.29  10.90  11.15 -12.893392  238820\n",
      "2000-01-10  11.40  11.41  11.02  11.27 -13.032155  272760\n",
      "...           ...    ...    ...    ...        ...     ...\n",
      "2001-07-03  10.25  10.30  10.15  10.20 -11.917643  549516\n",
      "2001-07-04  10.26  10.28  10.13  10.14 -11.847538  684621\n",
      "2001-07-05  10.12  10.19  10.09  10.14 -11.847538  429330\n",
      "2001-07-06  10.09  10.13  10.01  10.08 -11.777433  244451\n",
      "2001-07-09  10.00  10.14   9.91  10.10 -11.800801  475033\n",
      "\n",
      "[380 rows x 6 columns]\n",
      "preprocessed/yfinance/SOL.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\arraylike.py:397: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n",
      "Empty DataFrame\n",
      "Columns: [Open, High, Low, Close, Adj Close, Volume]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleja\\AppData\\Local\\Temp\\ipykernel_28836\\1811459781.py:23: FutureWarning: reindexing with a non-unique Index is deprecated and will raise in a future version.\n",
      "  ibex_historical_data = pd.DataFrame(ibex_historical_data)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reindex on an axis with duplicate labels",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleja\\Documents\\GitHub\\TFM-Algoritmo-con-redes-evolutivas\\ibex_data_processing_yfinance.ipynb Celda 20\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_yfinance.ipynb#X34sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_yfinance.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         ibex_historical_data[act_list[i]] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_yfinance.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m ibex_historical_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(ibex_historical_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_yfinance.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m table \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_pandas(ibex_historical_data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_yfinance.ipynb#X34sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m buf \u001b[39m=\u001b[39m BytesIO()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    630\u001b[0m     mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_mgr(\n\u001b[0;32m    631\u001b[0m         data, axes\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index, \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: columns}, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39mcopy\n\u001b[0;32m    632\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    635\u001b[0m     \u001b[39m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m     mgr \u001b[39m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, typ\u001b[39m=\u001b[39;49mmanager)\n\u001b[0;32m    637\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ma\u001b[39m.\u001b[39mMaskedArray):\n\u001b[0;32m    638\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mma\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmrecords\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    494\u001b[0m     arrays \u001b[39m=\u001b[39m [\n\u001b[0;32m    495\u001b[0m         x\n\u001b[0;32m    496\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m    497\u001b[0m         \u001b[39melse\u001b[39;00m x\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    498\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m    499\u001b[0m     ]\n\u001b[0;32m    500\u001b[0m     \u001b[39m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[1;32m--> 502\u001b[0m \u001b[39mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[39m=\u001b[39;49mdtype, typ\u001b[39m=\u001b[39;49mtyp, consolidate\u001b[39m=\u001b[39;49mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:125\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    122\u001b[0m         index \u001b[39m=\u001b[39m ensure_index(index)\n\u001b[0;32m    124\u001b[0m     \u001b[39m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     arrays \u001b[39m=\u001b[39m _homogenize(arrays, index, dtype)\n\u001b[0;32m    126\u001b[0m     \u001b[39m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    127\u001b[0m     \u001b[39m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    128\u001b[0m     \u001b[39m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    131\u001b[0m \n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     index \u001b[39m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\construction.py:607\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    603\u001b[0m         val \u001b[39m=\u001b[39m val\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    604\u001b[0m     \u001b[39mif\u001b[39;00m val\u001b[39m.\u001b[39mindex \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m index:\n\u001b[0;32m    605\u001b[0m         \u001b[39m# Forces alignment. No need to copy data since we\u001b[39;00m\n\u001b[0;32m    606\u001b[0m         \u001b[39m# are putting it into an ndarray later\u001b[39;00m\n\u001b[1;32m--> 607\u001b[0m         val \u001b[39m=\u001b[39m val\u001b[39m.\u001b[39;49mreindex(index, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    609\u001b[0m     val \u001b[39m=\u001b[39m val\u001b[39m.\u001b[39m_values\n\u001b[0;32m    610\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\series.py:4672\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4668\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   4669\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m'\u001b[39m\u001b[39m passed as both positional and keyword argument\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4670\u001b[0m         )\n\u001b[0;32m   4671\u001b[0m     kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mindex\u001b[39m\u001b[39m\"\u001b[39m: index})\n\u001b[1;32m-> 4672\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mreindex(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4966\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4963\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   4965\u001b[0m \u001b[39m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 4966\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reindex_axes(\n\u001b[0;32m   4967\u001b[0m     axes, level, limit, tolerance, method, fill_value, copy\n\u001b[0;32m   4968\u001b[0m )\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mreindex\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:4986\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   4981\u001b[0m new_index, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39mreindex(\n\u001b[0;32m   4982\u001b[0m     labels, level\u001b[39m=\u001b[39mlevel, limit\u001b[39m=\u001b[39mlimit, tolerance\u001b[39m=\u001b[39mtolerance, method\u001b[39m=\u001b[39mmethod\n\u001b[0;32m   4983\u001b[0m )\n\u001b[0;32m   4985\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m-> 4986\u001b[0m obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_reindex_with_indexers(\n\u001b[0;32m   4987\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   4988\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m   4989\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   4990\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   4991\u001b[0m )\n\u001b[0;32m   4992\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   4993\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\generic.py:5032\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[1;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[0;32m   5029\u001b[0m     indexer \u001b[39m=\u001b[39m ensure_platform_int(indexer)\n\u001b[0;32m   5031\u001b[0m \u001b[39m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[1;32m-> 5032\u001b[0m new_data \u001b[39m=\u001b[39m new_data\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[0;32m   5033\u001b[0m     index,\n\u001b[0;32m   5034\u001b[0m     indexer,\n\u001b[0;32m   5035\u001b[0m     axis\u001b[39m=\u001b[39;49mbaxis,\n\u001b[0;32m   5036\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m   5037\u001b[0m     allow_dups\u001b[39m=\u001b[39;49mallow_dups,\n\u001b[0;32m   5038\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   5039\u001b[0m )\n\u001b[0;32m   5040\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[0;32m   5041\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\internals\\managers.py:676\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    674\u001b[0m \u001b[39m# some axes don't allow reindexing with dups\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_dups:\n\u001b[1;32m--> 676\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes[axis]\u001b[39m.\u001b[39;49m_validate_can_reindex(indexer)\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[0;32m    679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequested axis not found in manager\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pandas\\core\\indexes\\base.py:4121\u001b[0m, in \u001b[0;36mIndex._validate_can_reindex\u001b[1;34m(self, indexer)\u001b[0m\n\u001b[0;32m   4119\u001b[0m \u001b[39m# trying to reindex on an axis with duplicates\u001b[39;00m\n\u001b[0;32m   4120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_as_unique \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(indexer):\n\u001b[1;32m-> 4121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"
     ]
    }
   ],
   "source": [
    "# CARGAMOS EL DATAFRAME CON TODOS LOS DATOS DE CIERRE DE TODOS LOS ACTIVOS DESDE 02/01/1991\n",
    "for i in range(len(raw_filepaths)):\n",
    "    \n",
    "    try:\n",
    "        stock_prices = pq.read_table(download_s3_parquet_file(s3, bucket_name,raw_filepaths[i])).to_pandas()\n",
    "        stock_prices.index = pd.to_datetime(stock_prices.index).strftime('%Y-%m-%d')\n",
    "        returns = np.log(stock_prices['Adj Close']).diff()[1:]\n",
    "        min_returns = returns.min().min()\n",
    "        \n",
    "        negative_adj_close = stock_prices[stock_prices['Adj Close']<0]\n",
    "        print(negative_adj_close)\n",
    "        if (negative_adj_close.empty):# | (min_returns > -1):\n",
    "            close_price = stock_prices['Adj Close']\n",
    "        else:\n",
    "            close_price = stock_prices['Close']\n",
    "            print(raw_filepaths[i])\n",
    "\n",
    "        close_price.index = pd.to_datetime(close_price.index).strftime('%Y-%m-%d')\n",
    "        ibex_historical_data[act_list[i]] = close_price\n",
    "    except:\n",
    "        ibex_historical_data[act_list[i]] = np.nan\n",
    "        \n",
    "ibex_historical_data = pd.DataFrame(ibex_historical_data)\n",
    "\n",
    "table = pa.Table.from_pandas(ibex_historical_data)\n",
    "buf = BytesIO()\n",
    "pq.write_table(table, buf)\n",
    "\n",
    "s3.Object(bucket_name, full_path).put(Body=buf.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['A3TV', 'ABG.P', 'ABG.P_1', 'ABG', 'ACR', 'ACX', 'AGR', 'AGS', 'AGS_1',\n",
       "        'AGS_2',\n",
       "        ...\n",
       "        'UNI', 'URA', 'URB', 'VAL', 'VAL_1', 'VDR', 'VIS', 'VIS_1', 'ZEL',\n",
       "        'ZOT'],\n",
       "       dtype='object', length=101),\n",
       " 101)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_loads = ibex_historical_data.columns[ibex_historical_data.isnull().values.all(axis=0)]\n",
    "failed_loads, len(failed_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3TV</th>\n",
       "      <th>ABE</th>\n",
       "      <th>ABG.P</th>\n",
       "      <th>ABG.P_1</th>\n",
       "      <th>ABG</th>\n",
       "      <th>ACE</th>\n",
       "      <th>ACR</th>\n",
       "      <th>ACS</th>\n",
       "      <th>ACX</th>\n",
       "      <th>ACX_1</th>\n",
       "      <th>...</th>\n",
       "      <th>URB</th>\n",
       "      <th>VAL</th>\n",
       "      <th>VAL_1</th>\n",
       "      <th>VDR</th>\n",
       "      <th>VIS</th>\n",
       "      <th>VIS_1</th>\n",
       "      <th>VIS_2</th>\n",
       "      <th>VIS_3</th>\n",
       "      <th>ZEL</th>\n",
       "      <th>ZOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.655523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.637537</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.573376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.636639</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.532304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.516951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.516951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.573376</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.783944</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.309999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.740000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.809999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.920000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.870001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6109 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A3TV  ABE  ABG.P  ABG.P_1  ABG       ACE  ACR        ACS  ACX  \\\n",
       "Date                                                                        \n",
       "2000-01-03   NaN  NaN    NaN      NaN  NaN  3.655523  NaN        NaN  NaN   \n",
       "2000-01-04   NaN  NaN    NaN      NaN  NaN  3.573376  NaN        NaN  NaN   \n",
       "2000-01-05   NaN  NaN    NaN      NaN  NaN  3.532304  NaN        NaN  NaN   \n",
       "2000-01-06   NaN  NaN    NaN      NaN  NaN       NaN  NaN        NaN  NaN   \n",
       "2000-01-07   NaN  NaN    NaN      NaN  NaN  3.573376  NaN        NaN  NaN   \n",
       "...          ...  ...    ...      ...  ...       ...  ...        ...  ...   \n",
       "2023-08-21   NaN  NaN    NaN      NaN  NaN       NaN  NaN  31.309999  NaN   \n",
       "2023-08-22   NaN  NaN    NaN      NaN  NaN       NaN  NaN  31.740000  NaN   \n",
       "2023-08-23   NaN  NaN    NaN      NaN  NaN       NaN  NaN  31.809999  NaN   \n",
       "2023-08-24   NaN  NaN    NaN      NaN  NaN       NaN  NaN  31.920000  NaN   \n",
       "2023-08-25   NaN  NaN    NaN      NaN  NaN       NaN  NaN  31.870001  NaN   \n",
       "\n",
       "               ACX_1  ...  URB  VAL  VAL_1  VDR  VIS  VIS_1  VIS_2  VIS_3  \\\n",
       "Date                  ...                                                   \n",
       "2000-01-03  3.637537  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2000-01-04  3.636639  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2000-01-05  3.516951  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2000-01-06  3.516951  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2000-01-07  3.783944  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "...              ...  ...  ...  ...    ...  ...  ...    ...    ...    ...   \n",
       "2023-08-21       NaN  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2023-08-22       NaN  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2023-08-23       NaN  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2023-08-24       NaN  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "2023-08-25       NaN  ...  NaN  NaN    NaN  NaN  NaN    NaN    NaN    NaN   \n",
       "\n",
       "            ZEL  ZOT  \n",
       "Date                  \n",
       "2000-01-03  NaN  NaN  \n",
       "2000-01-04  NaN  NaN  \n",
       "2000-01-05  NaN  NaN  \n",
       "2000-01-06  NaN  NaN  \n",
       "2000-01-07  NaN  NaN  \n",
       "...         ...  ...  \n",
       "2023-08-21  NaN  NaN  \n",
       "2023-08-22  NaN  NaN  \n",
       "2023-08-23  NaN  NaN  \n",
       "2023-08-24  NaN  NaN  \n",
       "2023-08-25  NaN  NaN  \n",
       "\n",
       "[6109 rows x 170 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibex_historical_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
