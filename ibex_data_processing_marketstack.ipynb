{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGAMOS LIBRERIAS\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import fastparquet\n",
    "import awswrangler as wr\n",
    "import os\n",
    "\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from io import BytesIO\n",
    "from pandas.tseries.offsets import BDay\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INICIALIZAMOS UNA SESION EN AWS\n",
    "session = boto3.Session(\n",
    "    aws_access_key_id=os.environ['S3_ACCESS_KEY'],\n",
    "    aws_secret_access_key=os.environ['S3_SECRET_KEY'],\n",
    "    region_name=os.environ['S3_REGION'])\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "bucket_name = 'stock-market-historical-data'\n",
    "pre_folder = 'preprocessed/marketstack/'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJETIVO DE ESTE NOTEBOOK:\n",
    "- DESCARGAR DE DISTINTOS ORIGENES LOS DATOS DE LOS ACTIVOS DEL IBEX35\n",
    "- COMPARAR LOS DATOS OBTENIDOS "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CARGA DE COMPOSICIÓN HISTÓRICA DE IBEX35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activo</th>\n",
       "      <th>Inclusion</th>\n",
       "      <th>Exclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACE</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2003-06-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACX</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1991-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ALB</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1991-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASL</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>1994-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BBV</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2000-01-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activo  Inclusion  Exclusion\n",
       "0    ACE 1991-01-02 2003-06-02\n",
       "1    ACX 1991-01-02 1991-07-01\n",
       "2    ALB 1991-01-02 1991-07-01\n",
       "3    ASL 1991-01-02 1994-01-03\n",
       "4    BBV 1991-01-02 2000-01-31"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LEEMOS EL FICHERO CON LA COMPOSICIÓN HISTORICA\n",
    "ibex_constituents = pd.read_excel('data_processing/Historical Composition IBEX35.xlsx')\n",
    "ibex_constituents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ibex_constituents['Exclusion'] -= BDay(1)\n",
    "\n",
    "# ibex_constituents['Inclusion'] = ibex_constituents['Inclusion'].dt.date\n",
    "# ibex_constituents['Exclusion'] = ibex_constituents['Exclusion'].dt.date\n",
    "\n",
    "# OBTENEMOS EL DIA ACTUAL\n",
    "today = datetime.date.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# COMPLETAMOS LOS DATOS NULOS EN EL FICHERO DE COMPOSICIÓN HISTORICA CON LA FECHA ACTUAL\n",
    "ibex_constituents.fillna(today,inplace=True)\n",
    "\n",
    "# DEFINIMOS UNA VARIABLE PARA TODOS LOS ACTIVOS\n",
    "activos = ibex_constituents.Activo\n",
    "ibex_constituents['Ticker'] = activos.apply(lambda x: x.split('_')[0])\n",
    "\n",
    "unique_activos = list(set(activos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibex_constituents.Ticker.replace('RAD','EZE',inplace=True)\n",
    "ibex_constituents.Ticker.replace('PUL','EBRO',inplace=True)\n",
    "ibex_constituents.Ticker.replace('EVA','EBRO',inplace=True)\n",
    "ibex_constituents.Ticker.replace('EBA','EBRO',inplace=True)\n",
    "ibex_constituents.Ticker.replace('BBV','BBVA',inplace=True)\n",
    "ibex_constituents.Ticker.replace('BBVAA','BBVA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activo</th>\n",
       "      <th>Inclusion</th>\n",
       "      <th>Exclusion</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>RAD</td>\n",
       "      <td>1999-04-19</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>EZE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activo  Inclusion  Exclusion Ticker\n",
       "78    RAD 1999-04-19 1999-07-01    EZE"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibex_constituents[ibex_constituents['Ticker'] == 'EZE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activo</th>\n",
       "      <th>Inclusion</th>\n",
       "      <th>Exclusion</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BKT</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>BKT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>IBE</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>IBE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>REP</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>REP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TEF</td>\n",
       "      <td>1991-01-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>TEF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACS</td>\n",
       "      <td>1998-04-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ACS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>FER</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>FER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>IDR</td>\n",
       "      <td>1999-07-01</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>IDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>BBVA</td>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>BBVA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ITX</td>\n",
       "      <td>2001-07-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ITX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>SAN_1</td>\n",
       "      <td>2001-11-01</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>SAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>ENG</td>\n",
       "      <td>2003-01-10</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ENG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>SAB</td>\n",
       "      <td>2004-07-01</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>SAB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>MAP_2</td>\n",
       "      <td>2006-07-25</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>MAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>GRF</td>\n",
       "      <td>2008-01-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>GRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>MTS</td>\n",
       "      <td>2009-05-05</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>MTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>AMS_1</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>AMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>IAG</td>\n",
       "      <td>2011-04-01</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>IAG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>CABK</td>\n",
       "      <td>2011-07-01</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>CABK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>SCYR_2</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>SCYR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>ELE_1</td>\n",
       "      <td>2014-12-22</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ELE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>ACX_2</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ACX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>AENA</td>\n",
       "      <td>2015-06-22</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>AENA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>ANA_2</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ANA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>MRL</td>\n",
       "      <td>2015-12-21</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>MRL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>CLNX</td>\n",
       "      <td>2016-06-21</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>CLNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>MEL</td>\n",
       "      <td>2016-08-08</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>MEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>COL_1</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>COL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>NTGY</td>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>NTGY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>SLR</td>\n",
       "      <td>2020-10-19</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>SLR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>FDR</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>ROVI</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ROVI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>RED</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>ANE</td>\n",
       "      <td>2022-06-20</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>ANE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>LOG</td>\n",
       "      <td>2022-12-19</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>LOG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>UNI_1</td>\n",
       "      <td>2022-12-27</td>\n",
       "      <td>2023-08-23</td>\n",
       "      <td>UNI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Activo  Inclusion  Exclusion Ticker\n",
       "5       BKT 1991-01-02 2023-08-23    BKT\n",
       "18      IBE 1991-01-02 2023-08-23    IBE\n",
       "21      REP 1991-01-02 2023-08-23    REP\n",
       "25      TEF 1991-01-02 2023-08-23    TEF\n",
       "71      ACS 1998-04-02 2023-08-23    ACS\n",
       "79      FER 1999-07-01 2023-08-23    FER\n",
       "80      IDR 1999-07-01 2023-08-23    IDR\n",
       "85     BBVA 2000-01-31 2023-08-23   BBVA\n",
       "95      ITX 2001-07-02 2023-08-23    ITX\n",
       "96    SAN_1 2001-11-01 2023-08-23    SAN\n",
       "101     ENG 2003-01-10 2023-08-23    ENG\n",
       "108     SAB 2004-07-01 2023-08-23    SAB\n",
       "116   MAP_2 2006-07-25 2023-08-23    MAP\n",
       "123     GRF 2008-01-02 2023-08-23    GRF\n",
       "129     MTS 2009-05-05 2023-08-23    MTS\n",
       "132   AMS_1 2011-01-03 2023-08-23    AMS\n",
       "133     IAG 2011-04-01 2023-08-23    IAG\n",
       "134    CABK 2011-07-01 2023-08-23   CABK\n",
       "141  SCYR_2 2022-06-20 2023-08-23   SCYR\n",
       "145   ELE_1 2014-12-22 2023-08-23    ELE\n",
       "146   ACX_2 2015-06-22 2023-08-23    ACX\n",
       "147    AENA 2015-06-22 2023-08-23   AENA\n",
       "148   ANA_2 2015-07-20 2023-08-23    ANA\n",
       "149     MRL 2015-12-21 2023-08-23    MRL\n",
       "150    CLNX 2016-06-21 2023-08-23   CLNX\n",
       "152     MEL 2016-08-08 2023-08-23    MEL\n",
       "153   COL_1 2017-06-16 2023-08-23    COL\n",
       "155    NTGY 2018-07-02 2023-08-23   NTGY\n",
       "161     SLR 2020-10-19 2023-08-23    SLR\n",
       "162     FDR 2021-03-29 2023-08-23    FDR\n",
       "163    ROVI 2021-12-20 2023-08-23   ROVI\n",
       "164     RED 2022-06-13 2023-08-23    RED\n",
       "165     ANE 2022-06-20 2023-08-23    ANE\n",
       "166     LOG 2022-12-19 2023-08-23    LOG\n",
       "167   UNI_1 2022-12-27 2023-08-23    UNI"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_constituents = ibex_constituents.loc[ibex_constituents['Exclusion'] == today]\n",
    "current_constituents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCARGA DE DATOS CON API DE MARKETSTACK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exchanges_data(api_token):\n",
    "    # OBTENEMOS TODOS LOS EXCHANGES\n",
    "    url = f'http://api.marketstack.com/v1/'\n",
    "    exchange_list = 'exchanges'\n",
    "\n",
    "    r = requests.get(\n",
    "                url+exchange_list,\n",
    "                params={\n",
    "                    'access_key':api_token\n",
    "                }\n",
    "            )\n",
    "\n",
    "    exchanges = pd.DataFrame(json.load(BytesIO(r.content))['data'])\n",
    "    return exchanges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exchanges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleja\\Documents\\GitHub\\TFM-Algoritmo-con-redes-evolutivas\\ibex_data_processing_marketstack.ipynb Celda 13\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_marketstack.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spain_ex_code \u001b[39m=\u001b[39m exchanges\u001b[39m.\u001b[39mloc[exchanges[\u001b[39m'\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mSpain\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mmic\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_marketstack.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m spain_ex_code\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exchanges' is not defined"
     ]
    }
   ],
   "source": [
    "spain_ex_code = exchanges.loc[exchanges['country']=='Spain','mic'].values[0]\n",
    "spain_ex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_list(api_token, exchange_code):\n",
    "    \n",
    "    url = f'http://api.marketstack.com/v1/'\n",
    "    symbol_list = 'tickers'\n",
    "\n",
    "    r = requests.get(url+symbol_list,\n",
    "                    params={\n",
    "                        'access_key': api_token,\n",
    "                        'exchange': exchange_code,\n",
    "                        'limit':1000\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    symbols = pd.DataFrame(json.load(BytesIO(r.content))['data'])\n",
    "    return symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eod_data(api_token, exchange_code, ticker, start_date, end_date, limit=1000):\n",
    "    url = f'http://api.marketstack.com/v1/'\n",
    "    eod_data = 'eod'\n",
    "    mstack_ticker = ticker+'.'+exchange_code\n",
    "    r = requests.get(url+eod_data,\n",
    "                            params={\n",
    "                                'access_key': api_token,\n",
    "                                'exchange': exchange_code,\n",
    "                                'symbols': mstack_ticker,\n",
    "                                'date_from': start_date,\n",
    "                                'date_to': end_date,\n",
    "                                'limit': limit\n",
    "                                }\n",
    "                            )\n",
    "    ticker_data = pd.DataFrame(json.load(BytesIO(r.content))['data'])\n",
    "    ticker_data.set_index('date', inplace=True)\n",
    "\n",
    "    return ticker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_parquet_to_s3(bucket_name, file_name, folder_name, dataframe):\n",
    "    full_path = folder_name + file_name + '.parquet'\n",
    "    s3 = boto3.resource('s3')\n",
    "    table = pa.Table.from_pandas(dataframe)\n",
    "    buf = BytesIO()\n",
    "    pq.write_table(table, buf)\n",
    "    s3.Object(bucket_name, full_path).put(Body=buf.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(stock_data, api_token, exchange_code, bucket_name, folder_name):\n",
    "    # REALIZAMOS LA DESCARGA DE LOS DATOS DE MARKETSTACK Y LOS CARGAMOS EN UN BUCKET DE S3\n",
    "    failed_loads = []\n",
    "\n",
    "    indexes = current_constituents.index\n",
    "\n",
    "    for i in indexes:\n",
    "        \n",
    "        try:\n",
    "            ticker = ibex_constituents.Ticker[i]\n",
    "            start_date = ibex_constituents.Inclusion[i]\n",
    "            end_date = ibex_constituents.Exclusion[i]\n",
    "            \n",
    "            file_name = ibex_constituents.Activo[i] +'.parquet'\n",
    "\n",
    "            total_days = (end_date.to_period('D') - start_date.to_period('D')).n/1000\n",
    "\n",
    "            stock_data = pd.DataFrame()\n",
    "\n",
    "            for _ in range(math.ceil(total_days)):\n",
    "                try:\n",
    "                    prov_end_date = start_date + datetime.timedelta(days=1000)\n",
    "                    if prov_end_date > end_date:\n",
    "                        ticker_data = get_eod_data(\n",
    "                                            API_TOKEN,\n",
    "                                            spain_ex_code,\n",
    "                                            ticker,\n",
    "                                            start_date,\n",
    "                                            end_date\n",
    "                                            )\n",
    "                    else:\n",
    "                        ticker_data = get_eod_data(\n",
    "                                            API_TOKEN,\n",
    "                                            spain_ex_code,\n",
    "                                            ticker,\n",
    "                                            start_date,\n",
    "                                            prov_end_date\n",
    "                                            )\n",
    "\n",
    "                    stock_data = pd.concat([stock_data, ticker_data], axis=0)\n",
    "                    start_date = prov_end_date + datetime.timedelta(days=1)\n",
    "                except:\n",
    "                    start_date = prov_end_date + datetime.timedelta(days=1)\n",
    "                    continue\n",
    "                    \n",
    "            upload_parquet_to_s3(bucket_name, file_name, pre_folder, stock_data)\n",
    "            print(ibex_constituents.Activo[i])\n",
    "        except:\n",
    "            print('failed')\n",
    "            failed_loads.append(ticker)\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n",
      "1999-04-19 00:00:00 2002-01-13 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'> <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "RAD\n"
     ]
    }
   ],
   "source": [
    "# REALIZAMOS LA DESCARGA DE LOS DATOS DE MARKETSTACK Y LOS CARGAMOS EN UN BUCKET DE S3\n",
    "failed_loads = []\n",
    "\n",
    "indexes = current_constituents.index\n",
    "\n",
    "for i in indexes:\n",
    "    \n",
    "    try:\n",
    "        ticker = ibex_constituents.Ticker[i]\n",
    "        start_date = ibex_constituents.Inclusion[i]\n",
    "        end_date = ibex_constituents.Exclusion[i]\n",
    "        \n",
    "        file_name = ibex_constituents.Activo[i] +'.parquet'\n",
    "\n",
    "        total_days = (end_date.to_period('D') - start_date.to_period('D')).n/1000\n",
    "\n",
    "        stock_data = pd.DataFrame()\n",
    "\n",
    "        for _ in range(math.ceil(total_days)):\n",
    "            try:\n",
    "                prov_end_date = start_date + datetime.timedelta(days=1000)\n",
    "                if prov_end_date > end_date:\n",
    "                    ticker_data = get_eod_data(\n",
    "                                        API_TOKEN,\n",
    "                                        spain_ex_code,\n",
    "                                        ticker,\n",
    "                                        start_date,\n",
    "                                        end_date\n",
    "                                        )\n",
    "                else:\n",
    "                    ticker_data = get_eod_data(\n",
    "                                        API_TOKEN,\n",
    "                                        spain_ex_code,\n",
    "                                        ticker,\n",
    "                                        start_date,\n",
    "                                        prov_end_date\n",
    "                                        )\n",
    "\n",
    "                stock_data = pd.concat([stock_data, ticker_data], axis=0)\n",
    "                start_date = prov_end_date + datetime.timedelta(days=1)\n",
    "            except:\n",
    "                start_date = prov_end_date + datetime.timedelta(days=1)\n",
    "                continue\n",
    "                \n",
    "        upload_parquet_to_s3(bucket_name, file_name, pre_folder, stock_data)\n",
    "        print(ibex_constituents.Activo[i])\n",
    "    except:\n",
    "        print('failed')\n",
    "        failed_loads.append(ticker)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_list(bucket_name, folder_name):\n",
    "        s3 = boto3.resource('s3')\n",
    "        pre_path = bucket_name + pre_folder\n",
    "        objects_dict = s3_client.list_objects_v2(\n",
    "                Bucket=bucket_name,\n",
    "                Prefix=pre_folder)\n",
    "        filepaths = [item['Key'] for item in objects_dict['Contents'] if item['Key'].endswith('.parquet')]\n",
    "        act_list = [i.split('/')[-1].replace('.parquet','') for i in filepaths]\n",
    "        return filepaths, act_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_constituents_filepath = [pre_folder + act + '.parquet' for act in current_constituents.Activo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibex_historical_data = {}\n",
    "processed_folder = 'processed/marketstack/'\n",
    "file_name = 'ibex_historical_data'\n",
    "full_path = processed_folder + file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_s3_parquet_file(s3, bucket, key):\n",
    "    buffer = BytesIO()\n",
    "    s3.Object(bucket, key).download_fileobj(buffer)\n",
    "    return buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\aleja\\Documents\\GitHub\\TFM-Algoritmo-con-redes-evolutivas\\ibex_data_processing_marketstack.ipynb Celda 23\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/aleja/Documents/GitHub/TFM-Algoritmo-con-redes-evolutivas/ibex_data_processing_marketstack.ipynb#Y123sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m act_data[\u001b[39m'\u001b[39;49m\u001b[39msymbol\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49munique()\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "current_constituents_filepathsplit('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessed/marketstack/BKT.parquet\n",
      "preprocessed/marketstack/IBE.parquet\n",
      "preprocessed/marketstack/REP.parquet\n",
      "preprocessed/marketstack/TEF.parquet\n",
      "preprocessed/marketstack/ACS.parquet\n",
      "preprocessed/marketstack/FER.parquet\n",
      "preprocessed/marketstack/IDR.parquet\n",
      "preprocessed/marketstack/BBVA.parquet\n",
      "preprocessed/marketstack/ITX.parquet\n",
      "preprocessed/marketstack/SAN_1.parquet\n",
      "preprocessed/marketstack/ENG.parquet\n",
      "preprocessed/marketstack/SAB.parquet\n",
      "preprocessed/marketstack/MAP_2.parquet\n",
      "preprocessed/marketstack/GRF.parquet\n",
      "preprocessed/marketstack/MTS.parquet\n",
      "preprocessed/marketstack/AMS_1.parquet\n",
      "preprocessed/marketstack/IAG.parquet\n",
      "preprocessed/marketstack/CABK.parquet\n",
      "preprocessed/marketstack/SCYR_2.parquet\n",
      "preprocessed/marketstack/ELE_1.parquet\n",
      "preprocessed/marketstack/ACX_2.parquet\n",
      "preprocessed/marketstack/AENA.parquet\n",
      "preprocessed/marketstack/ANA_2.parquet\n",
      "preprocessed/marketstack/MRL.parquet\n",
      "preprocessed/marketstack/CLNX.parquet\n",
      "preprocessed/marketstack/MEL.parquet\n",
      "preprocessed/marketstack/COL_1.parquet\n",
      "preprocessed/marketstack/NTGY.parquet\n",
      "preprocessed/marketstack/SLR.parquet\n",
      "preprocessed/marketstack/FDR.parquet\n",
      "preprocessed/marketstack/ROVI.parquet\n",
      "preprocessed/marketstack/RED.parquet\n",
      "preprocessed/marketstack/ANE.parquet\n",
      "preprocessed/marketstack/LOG.parquet\n",
      "preprocessed/marketstack/UNI_1.parquet\n"
     ]
    }
   ],
   "source": [
    "# REALIZAMOS LA DESCARGA DE LOS DATOS DE MARKETSTACK Y LOS CARGAMOS EN UN BUCKET DE S3\n",
    "failed_loads = []\n",
    "act_list = current_constituents.Activo.values\n",
    "for i in range(len(current_constituents_filepath)):\n",
    "    act_data = pq.read_table(download_s3_parquet_file(s3, bucket_name, current_constituents_filepath[i])).to_pandas()\n",
    "    act_data.index = pd.to_datetime(act_data.index)\n",
    "    act_data.sort_index(inplace=True)\n",
    "    date = act_data.index[-1] + datetime.timedelta(days=1)\n",
    "    if (pd.to_datetime(today, utc=True) - date).days > 1:\n",
    "        new_data = get_eod_data(\n",
    "                            API_TOKEN,\n",
    "                            'BMEX',\n",
    "                            current_constituents.Ticker.iloc[i],\n",
    "                            date.strftime('%Y-%m-%d'),\n",
    "                            today\n",
    "                            )\n",
    "        new_data.index = pd.to_datetime(new_data.index)\n",
    "        act_data = pd.DataFrame(act_data)\n",
    "        act_data = pd.concat([act_data,new_data], axis=0)\n",
    "        act_data.sort_index(inplace=True)\n",
    "    \n",
    "    else:    \n",
    "        continue\n",
    "    print(current_constituents_filepath[i])\n",
    "    upload_parquet_to_s3(bucket_name, act_list[i], pre_folder, act_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filepaths, act_list = get_file_list(bucket_name,pre_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGAMOS EL DATAFRAME CON TODOS LOS DATOS DE CIERRE DE TODOS LOS ACTIVOS DESDE 02/01/1991\n",
    "ibex_historical_data = {}\n",
    "pro_folder = 'processed/marketstack/'\n",
    "file_name = 'ibex_historical_data'\n",
    "# full_path = processed_folder + file_name\n",
    "\n",
    "for i in range(len(raw_filepaths)):\n",
    "\n",
    "    try:\n",
    "        close_price = pq.read_table(download_s3_parquet_file(s3, bucket_name,raw_filepaths[i])).to_pandas()['adj_close']\n",
    "        close_price.index = pd.to_datetime(close_price.index).strftime('%Y-%m-%d')\n",
    "        ibex_historical_data[act_list[i]] = close_price\n",
    "    except:\n",
    "        ibex_historical_data[act_list[i]] = np.nan\n",
    "\n",
    "ibex_historical_data = pd.DataFrame(ibex_historical_data)\n",
    "upload_parquet_to_s3(bucket_name, file_name, pro_folder, ibex_historical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A3TV</th>\n",
       "      <th>ABE</th>\n",
       "      <th>ABG.P</th>\n",
       "      <th>ABG.P_1</th>\n",
       "      <th>ABG</th>\n",
       "      <th>ACE</th>\n",
       "      <th>ACR</th>\n",
       "      <th>ACS</th>\n",
       "      <th>ACX</th>\n",
       "      <th>ACX_1</th>\n",
       "      <th>...</th>\n",
       "      <th>URB</th>\n",
       "      <th>VAL</th>\n",
       "      <th>VAL_1</th>\n",
       "      <th>VDR</th>\n",
       "      <th>VIS</th>\n",
       "      <th>VIS_1</th>\n",
       "      <th>VIS_2</th>\n",
       "      <th>VIS_3</th>\n",
       "      <th>ZEL</th>\n",
       "      <th>ZOT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-08-16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2025</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.9683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-08-17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2035</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-08-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2010</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.1276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-08-19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1961</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-08-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1877</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.74</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7610 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            A3TV  ABE  ABG.P  ABG.P_1  ABG  ACE  ACR    ACS  ACX   ACX_1  ...  \\\n",
       "date                                                                      ...   \n",
       "1993-08-16   NaN  NaN    NaN      NaN  NaN  NaN  NaN    NaN  NaN  1.2025  ...   \n",
       "1993-08-17   NaN  NaN    NaN      NaN  NaN  NaN  NaN    NaN  NaN  1.2035  ...   \n",
       "1993-08-18   NaN  NaN    NaN      NaN  NaN  NaN  NaN    NaN  NaN  1.2010  ...   \n",
       "1993-08-19   NaN  NaN    NaN      NaN  NaN  NaN  NaN    NaN  NaN  1.1961  ...   \n",
       "1993-08-20   NaN  NaN    NaN      NaN  NaN  NaN  NaN    NaN  NaN  1.1877  ...   \n",
       "...          ...  ...    ...      ...  ...  ...  ...    ...  ...     ...  ...   \n",
       "2023-08-18   NaN  NaN    NaN      NaN  NaN  NaN  NaN  31.30  NaN     NaN  ...   \n",
       "2023-08-21   NaN  NaN    NaN      NaN  NaN  NaN  NaN  31.31  NaN     NaN  ...   \n",
       "2023-08-22   NaN  NaN    NaN      NaN  NaN  NaN  NaN  31.74  NaN     NaN  ...   \n",
       "2023-08-23   NaN  NaN    NaN      NaN  NaN  NaN  NaN  31.75  NaN     NaN  ...   \n",
       "2023-08-24   NaN  NaN    NaN      NaN  NaN  NaN  NaN  31.92  NaN     NaN  ...   \n",
       "\n",
       "            URB  VAL  VAL_1  VDR     VIS  VIS_1  VIS_2  VIS_3  ZEL     ZOT  \n",
       "date                                                                        \n",
       "1993-08-16  NaN  NaN    NaN  NaN  2.9683    NaN    NaN    NaN  NaN  0.4146  \n",
       "1993-08-17  NaN  NaN    NaN  NaN  3.0440    NaN    NaN    NaN  NaN  0.4307  \n",
       "1993-08-18  NaN  NaN    NaN  NaN  3.1276    NaN    NaN    NaN  NaN  0.4421  \n",
       "1993-08-19  NaN  NaN    NaN  NaN  3.0608    NaN    NaN    NaN  NaN  0.4421  \n",
       "1993-08-20  NaN  NaN    NaN  NaN  3.0440    NaN    NaN    NaN  NaN  0.4452  \n",
       "...         ...  ...    ...  ...     ...    ...    ...    ...  ...     ...  \n",
       "2023-08-18  NaN  NaN    NaN  NaN     NaN    NaN    NaN    NaN  NaN     NaN  \n",
       "2023-08-21  NaN  NaN    NaN  NaN     NaN    NaN    NaN    NaN  NaN     NaN  \n",
       "2023-08-22  NaN  NaN    NaN  NaN     NaN    NaN    NaN    NaN  NaN     NaN  \n",
       "2023-08-23  NaN  NaN    NaN  NaN     NaN    NaN    NaN    NaN  NaN     NaN  \n",
       "2023-08-24  NaN  NaN    NaN  NaN     NaN    NaN    NaN    NaN  NaN     NaN  \n",
       "\n",
       "[7610 rows x 170 columns]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibex_historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['A3TV', 'ABE', 'ABG.P', 'ABG.P_1', 'ACE', 'ACR', 'ACX', 'AGR', 'AGS',\n",
       "        'AGS_1', 'AGS_2', 'AGS_3', 'ALB', 'ALB_1', 'ALT', 'AMS', 'ARA', 'ARG',\n",
       "        'ASL', 'AUM', 'AZC', 'AZC_1', 'BCH', 'BTO', 'BTO_1', 'BTO_2', 'CAN',\n",
       "        'CAR', 'CEN', 'CEP', 'CEP_1', 'CIN', 'CRF', 'CRI', 'CRI_1', 'CRI_2',\n",
       "        'CTE', 'CTF', 'CTG', 'CUB', 'DRC', 'EBRO_1', 'ECR', 'ELE', 'EXT', 'FAD',\n",
       "        'FEC', 'FOC', 'GAM', 'GAM_1', 'GAS', 'GES', 'GES_1', 'GPP', 'HHU',\n",
       "        'HHU_1', 'HID', 'HIS', 'IBLA', 'IBR', 'JAZ', 'LOR', 'MVC', 'MVC_1',\n",
       "        'OHLA', 'PMD', 'POP', 'PRY', 'SAR', 'SCH', 'SEV', 'SGC', 'SOL', 'SYV',\n",
       "        'SYV_1', 'TAB', 'TEM', 'TPI', 'TPZ', 'TRR', 'TRR_1', 'UNF', 'UNI',\n",
       "        'URA', 'URB', 'VAL', 'VAL_1', 'VDR', 'ZEL'],\n",
       "       dtype='object'),\n",
       " 89)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed_loads = ibex_historical_data.columns[ibex_historical_data.isnull().values.all(axis=0)]\n",
    "failed_loads, len(failed_loads)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
